{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import rppg\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_script(name, model, root_dir, root_dir_val=None, clip=False, clip_length=64, batch_size=4, num_epochs=30):\n",
    "    \"\"\"\n",
    "    Train and test the given model on the given frame-level dataset. If root_dir_val is given, then root_dir is the directory of the training set. Otherwise, the dataset at root_dir is split into training and validation sets.\n",
    "    :param name: Name of the experiment\n",
    "    :param root_dir: Root directory of the (entire/training) dataset\n",
    "    :param model: Model to train and test\n",
    "    :param root_dir_val: Root directory of the validation dataset\n",
    "    :param clip: If False, train and test on frame-level dataset. If True, train and test on clip-level dataset.\n",
    "    \"\"\"\n",
    "    # Create experiment directory\n",
    "    exp_dir = os.path.join(\"results\", name)\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    if not clip:\n",
    "        if root_dir_val is None:\n",
    "            # Load dataset\n",
    "            dataset = rppg.rPPGFrameDataset(root_dir, transform=transforms.ToTensor())\n",
    "\n",
    "            # Split dataset into training and validation sets\n",
    "            train_size = int(0.8 * len(dataset))\n",
    "            val_size = len(dataset) - train_size\n",
    "            train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "        else:\n",
    "            # Load training and validation datasets\n",
    "            train_dataset = rppg.rPPGFrameDataset(root_dir, transform=transforms.ToTensor())\n",
    "            val_dataset = rppg.rPPGFrameDataset(root_dir_val, transform=transforms.ToTensor())\n",
    "    else:\n",
    "        if root_dir_val is None:\n",
    "            # Load dataset\n",
    "            dataset = rppg.rPPGClipDataset(root_dir, clip_length=clip_length, transform=transforms.ToTensor())\n",
    "\n",
    "            # Split dataset into training and validation sets\n",
    "            train_size = int(0.8 * len(dataset))\n",
    "            val_size = len(dataset) - train_size\n",
    "            train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "        else:\n",
    "            # Load training and validation datasets\n",
    "            train_dataset = rppg.rPPGClipDataset(root_dir, clip_length=clip_length, transform=transforms.ToTensor())\n",
    "            val_dataset = rppg.rPPGClipDataset(root_dir_val, clip_length=clip_length, transform=transforms.ToTensor())\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Print dataset sizes\n",
    "    if not clip:\n",
    "        print(f\"Training set size: {len(train_dataset) * batch_size} frames\")\n",
    "        print(f\"Validation set size: {len(val_dataset) * batch_size} frames\")\n",
    "    else:\n",
    "        print(f\"Training set size: {len(train_dataset) * batch_size} clips\")\n",
    "        print(f\"Validation set size: {len(val_dataset) * batch_size} clips\")\n",
    "\n",
    "    # Create model\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Create loss function and optimiser\n",
    "    criterion = nn.L1Loss()\n",
    "    optimiser = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train model\n",
    "    best_model, train_losses, val_losses = rppg.train_model(model, train_loader, val_loader, criterion, optimiser, num_epochs, device=device)\n",
    "\n",
    "    # Save model\n",
    "    torch.save(best_model.state_dict(), os.path.join(exp_dir, \"model.pt\"))\n",
    "\n",
    "    # Test model\n",
    "    test_loss, predictions, labels = rppg.test_model(best_model, val_loader, criterion, device=device)\n",
    "\n",
    "    # Save losses, predictions, and labels\n",
    "    np.savez(os.path.join(exp_dir, \"metrics.npz\"), train_losses=train_losses, val_losses=val_losses, test_loss=test_loss, predictions=predictions, labels=labels)\n",
    "\n",
    "    # Plot losses\n",
    "    rppg.plot_losses(train_losses, val_losses)\n",
    "\n",
    "    # Plot predictions vs labels\n",
    "    rppg.plot_predictions(predictions, labels, clip=clip)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MSc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
